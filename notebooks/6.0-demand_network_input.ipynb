{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform Demand data, so it can be used by a Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy import spatial\n",
    "from typing import Tuple\n",
    "\n",
    "EMBEDDING_DIM = 50"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T12:20:27.138744Z",
     "start_time": "2023-05-10T12:20:27.132966Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/uclm/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download wordnet if not already downloaded\n",
    "nltk.download('wordnet')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T12:15:35.955882Z",
     "start_time": "2023-05-10T12:15:35.796690Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['madrid', 'guadalajara', 'calatayud', 'zaragoza', 'lleida', 'tarragona', 'barcelona', 'girona', 'figueres']]\n"
     ]
    }
   ],
   "source": [
    "from src.robin.supply.entities import Supply\n",
    "\n",
    "path_config_supply = '../configs/test_case/supply_data.yml'\n",
    "\n",
    "supply = Supply.from_yaml(path_config_supply)\n",
    "\n",
    "# Get set of corridors\n",
    "corridors = []\n",
    "for service in supply.services:\n",
    "    if service.line.corridor not in corridors:\n",
    "        corridors.append(service.line.corridor)\n",
    "\n",
    "# Get set of paths\n",
    "paths = []\n",
    "for corridor in corridors:\n",
    "    for path in corridor.paths:\n",
    "        if path not in paths:\n",
    "            paths.append(path)\n",
    "\n",
    "# Parse paths of Station objects to paths of station mame\n",
    "paths = [[station.name.replace(\"-\", \" \").split(\" \")[0].lower() for station in path] for path in paths]\n",
    "print(paths)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T12:15:38.216322Z",
     "start_time": "2023-05-10T12:15:38.036259Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def get_word_syn(word: str) -> str:\n",
    "    \"\"\"\n",
    "    Get a random synonym of a word\n",
    "\n",
    "    Args:\n",
    "        word (str): Word to get the synonym from\n",
    "\n",
    "    Returns:\n",
    "        str: Synonym of the word\n",
    "    \"\"\"\n",
    "    word_synset = wordnet.synsets(word)\n",
    "    if len(word_synset) > 0:\n",
    "        station_synset = word_synset[0]\n",
    "        station_lemmas = station_synset.lemmas()\n",
    "        if len(station_lemmas) > 0:\n",
    "            word_lemma = random.choice(station_lemmas)\n",
    "            return word_lemma.name().lower()\n",
    "\n",
    "    return word\n",
    "\n",
    "def get_random_pair(paths: list[list]) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Get a random pair of stations from a path\n",
    "\n",
    "    Args:\n",
    "        paths (list[list]): List of stations\n",
    "\n",
    "    Returns:\n",
    "        Tuple[str, str]: Tuple with the origin and destination stations\n",
    "    \"\"\"\n",
    "    random_path = random.choice(paths)  # Choose a random path\n",
    "\n",
    "    origin_index = random.randint(0, len(random_path) - 2)  # Choose a random origin station\n",
    "    destination_index = random.randint(origin_index + 1, len(random_path) - 1)  # Choose a random destination station\n",
    "\n",
    "    origin_station = random_path[origin_index]\n",
    "    destination_station = random_path[destination_index]\n",
    "    return origin_station, destination_station"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T12:16:08.634936Z",
     "start_time": "2023-05-10T12:16:08.629751Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "stations_csv_path = f'../data/renfe/renfe_stations.csv'\n",
    "\n",
    "def get_renfe_station_id(adif_id: str, stations_df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Returns the Station name given the Adif station id.\n",
    "\n",
    "    Args:\n",
    "        adif_id (str): Adif station id.\n",
    "        stations_df (pd.DataFrame): Dataframe with the stations' information.\n",
    "\n",
    "    Returns:\n",
    "        str: Station name.\n",
    "    \"\"\"\n",
    "    station_name = stations_df[stations_df['stop_id'] == adif_id]['stop_name'].values[0]\n",
    "    station_name = station_name.replace(\"-\", \" \").split(\" \")[0].lower()\n",
    "    return station_name\n",
    "\n",
    "stations_df = pd.read_csv(stations_csv_path, dtype={'stop_id': str, 'renfe_id': str})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T09:49:41.355197Z",
     "start_time": "2023-05-10T09:49:41.338526Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   origin destination user_pattern        arrival_date\n",
      "0  madrid      girona     business 2022-07-27 15:50:00\n",
      "1  lleida   barcelona      tourist 2030-12-18 00:41:00\n",
      "2  madrid   calatayud     business 2027-11-09 08:27:00\n",
      "3  madrid      lleida      student 2029-12-29 07:58:00\n",
      "4  lleida   barcelona     business 2030-06-05 16:27:00\n",
      "                                        arrival_date  \\\n",
      "0  [2022.0, 7.0, 27.0, 15.0, 50.0, 0.0, 0.0, 0.0,...   \n",
      "1  [2030.0, 12.0, 18.0, 0.0, 41.0, 0.0, 0.0, 0.0,...   \n",
      "2  [2027.0, 11.0, 9.0, 8.0, 27.0, 0.0, 0.0, 0.0, ...   \n",
      "3  [2029.0, 12.0, 29.0, 7.0, 58.0, 0.0, 0.0, 0.0,...   \n",
      "4  [2030.0, 6.0, 5.0, 16.0, 27.0, 0.0, 0.0, 0.0, ...   \n",
      "\n",
      "                                         scaled_date  \n",
      "0  [0.111114501953125, 0.5454545021057129, 0.8666...  \n",
      "1  [1.0, 1.0, 0.5666666626930237, 0.0, 0.69491523...  \n",
      "2  [0.6666717529296875, 0.9090908765792847, 0.266...  \n",
      "3  [0.888885498046875, 1.0, 0.9333333373069763, 0...  \n",
      "4  [1.0, 0.4545454680919647, 0.13333334028720856,...  \n"
     ]
    }
   ],
   "source": [
    "n_passengers = 1000\n",
    "\n",
    "pairs = []\n",
    "for _ in range(n_passengers):\n",
    "    pairs.append(get_random_pair(paths))\n",
    "\n",
    "df = pd.DataFrame(pairs, columns=['origin', 'destination'])\n",
    "\n",
    "user_patterns = (\"business\", \"student\", \"tourist\")\n",
    "\n",
    "df['user_pattern'] = [random.choice(user_patterns) for _ in range(n_passengers)]\n",
    "\n",
    "random_timedelta = lambda: datetime.timedelta(days=random.randint(0, 365*10), hours=random.randint(0, 24), minutes=random.randint(0, 60))\n",
    "df['arrival_date'] = [datetime.datetime(2021, 1, 1) + random_timedelta() for _ in range(n_passengers)]\n",
    "print(df.head())\n",
    "\n",
    "df_embedding = pd.DataFrame()\n",
    "df_embedding['arrival_date'] = df['arrival_date'].apply(lambda x: np.asarray([x.year, x.month, x.day, x.hour, x.minute] + [0.0] * (EMBEDDING_DIM - 5), dtype=np.float32))\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(np.array(df_embedding['arrival_date'].tolist()))\n",
    "df_embedding['scaled_date'] = scaled_data.tolist()\n",
    "print(df_embedding.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T13:05:21.211401Z",
     "start_time": "2023-05-10T13:05:21.200427Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'student', 'zaragoza', 'guadalajara', 'calatayud', 'business', 'madrid', 'barcelona', 'figueres', 'tarragona', 'girona', 'lleida', 'tourist'}\n"
     ]
    }
   ],
   "source": [
    "# Get bag of words\n",
    "words_set = set(df[['origin', 'destination', 'user_pattern', ]].values.flatten())\n",
    "\n",
    "print(words_set)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T13:05:26.854933Z",
     "start_time": "2023-05-10T13:05:26.846490Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n",
      "student [-1.0729    0.94103   0.084904 -1.0766    0.42866   0.099877 -0.51081\n",
      " -0.24961  -0.30883   0.19553   0.1965   -0.73152   0.096916 -0.062686\n",
      "  0.12078  -0.72384  -0.382     0.6934    0.32956   0.40244   0.53485\n",
      "  0.91781  -0.44553   0.71804  -0.13635  -1.6906    0.15818  -1.2367\n",
      " -1.2278   -0.058566  2.7544    0.18672  -0.263    -1.2792    0.16992\n",
      "  0.40748   0.12248   0.11211   0.78318   0.036392 -0.40808  -0.058474\n",
      " -0.27932   0.33035   0.52384  -1.0487    0.27565   0.0363    0.048604\n",
      "  0.28239 ]\n",
      "zaragoza [ 1.0642    0.089939 -0.28715   0.82471   0.31063  -1.4798    0.12028\n",
      "  0.7449   -1.2919    0.39737   0.4715   -0.53483  -0.48049  -1.2998\n",
      "  0.32826  -1.3085   -0.67916  -0.20625  -0.7232    0.41638  -1.2895\n",
      " -0.69963  -0.23631   0.70175  -0.61498   0.20193   1.329     0.25294\n",
      " -0.093715 -0.16535   0.99605   1.2007   -0.26729  -0.42035  -0.15881\n",
      "  0.63906  -0.73977   1.3119    0.61136  -0.59197   1.3032    0.16094\n",
      " -0.027686 -0.9412   -0.68288   0.65116   0.47976  -0.32516   1.3912\n",
      " -0.50467 ]\n",
      "guadalajara [ 0.66454   -0.030792  -0.65976    1.0981    -0.27973   -1.0009\n",
      " -0.2335     0.24978   -0.32826    1.244      0.93494   -1.4364\n",
      "  0.070134  -0.27999    0.48562   -1.2171    -1.0182     0.5233\n",
      " -0.81994    0.722     -1.0295    -0.50485    0.10219    0.77464\n",
      " -1.4905    -0.55574    0.13152    0.42089   -0.31912   -1.5303\n",
      "  0.3949     0.33945   -0.87748   -0.75725   -0.043081  -0.26023\n",
      " -0.54686    0.70108    0.68176    0.24399    0.056761  -0.0076331\n",
      "  0.66436   -1.1159    -0.41312    0.71485    0.17968   -0.27269\n",
      "  0.030796  -0.4465   ]\n",
      "calatayud [-0.6165     0.22867    0.12732    0.60427   -0.7213    -0.81453\n",
      "  1.3852     0.60059    0.17072    0.95024    0.20744   -0.45372\n",
      "  0.6271    -0.42923    0.25115   -0.66835   -0.02053    0.36235\n",
      "  0.06391    0.48771   -0.74967   -0.72486   -0.12697    0.068176\n",
      "  0.15597   -0.20094    0.60762    0.18272    0.48829   -0.8197\n",
      " -1.4656     0.0081439 -0.16165   -0.37037   -0.6043     0.62072\n",
      " -0.45622    1.2072     0.034754   1.0117     0.65683    0.61171\n",
      "  1.188      0.10198   -0.7492     0.091471  -0.39347   -1.0623\n",
      "  0.65213   -1.0082   ]\n",
      "business [ 0.023693  0.13316   0.023131  0.49833   0.026874 -0.43252  -1.1364\n",
      " -0.82001   0.22388  -0.032119 -0.069651  0.39857  -0.58275   0.095008\n",
      " -0.023643  0.23237  -0.42441   0.65709   0.57802  -0.51602   1.8253\n",
      "  0.12951  -0.61773   0.39281  -0.35754  -1.6778   -0.45201  -0.47075\n",
      "  0.19487   0.35828   3.6034    0.32865   0.47288  -0.33787  -0.46234\n",
      " -0.51628  -1.3755    0.70789   0.4648   -0.16186  -0.0961   -0.28523\n",
      "  0.30047   0.50902   0.081356 -0.015639 -0.51021   0.34585   0.24201\n",
      "  0.82237 ]\n",
      "madrid [ 1.3315     0.72181   -0.060088   0.43948    0.18419   -1.5083\n",
      " -0.48125    0.46037   -1.4088     1.2701     0.68031   -0.59232\n",
      " -1.6325    -0.30376    0.87685   -0.75531   -0.37583   -0.5363\n",
      " -1.0669     0.45537   -0.66694    0.43001   -0.69525    0.67518\n",
      " -0.93783   -0.67933    1.1104     0.37576   -0.36894   -0.083185\n",
      "  2.0346     0.96286   -0.56629   -0.7787    -0.10705   -0.14102\n",
      "  0.07384    0.62338    0.20366    0.0076751  0.71088    0.01501\n",
      "  0.53186   -0.82256   -0.35087    0.30876   -0.065328   0.23722\n",
      "  1.4692    -0.93469  ]\n",
      "barcelona [ 0.68944   1.2217   -0.23655   0.36109  -0.62116  -1.0075   -0.52565\n",
      "  0.65766  -1.2764    1.1286    1.1386   -0.36088  -1.3849   -0.58442\n",
      "  0.9772   -0.35103   0.29237  -0.27426  -1.3109   -0.015967 -1.0695\n",
      "  0.11901  -0.56335   0.49648  -0.44571  -0.47566   0.79045   0.42923\n",
      " -0.76743  -0.14029   1.7552    1.3342   -0.42864  -0.29125  -0.2056\n",
      "  0.21055   0.099324  1.4187    0.34068  -0.4477    1.0795    0.10387\n",
      "  0.15772  -0.51013  -0.50933   0.25395   0.050859 -0.084172  0.69738\n",
      " -1.192   ]\n",
      "figueres [ 0.90565   0.46405  -0.48596   0.42419  -0.8704    0.066207 -0.50311\n",
      " -0.042838 -0.69957  -0.67761   1.1499    0.2294   -0.054796 -0.22567\n",
      " -0.34964  -0.62358  -0.8379    0.19477   0.94323   0.065511 -2.18\n",
      "  0.12716  -0.45373  -0.12187   0.726     0.2507    0.87852   0.68919\n",
      " -1.6939   -0.42493  -0.59557   0.82288  -0.67005  -0.50038  -0.64736\n",
      " -0.87874  -0.13023   0.45906   0.83137  -0.011592 -0.59417  -0.31512\n",
      "  0.3037   -1.198    -0.38814   0.31753  -0.074266 -0.15812   0.73706\n",
      " -0.11858 ]\n",
      "tarragona [ 1.3885   -0.089092 -1.0508    0.058438 -0.50411  -0.80545   0.80153\n",
      "  0.82715  -1.2087    0.45195   0.80519  -1.5551    0.34254  -0.75674\n",
      "  0.028514 -0.10778  -0.059228  0.51951  -0.45246   0.96256  -0.94067\n",
      " -0.78372  -0.36429   1.6069   -1.3246    0.48912   0.53017   0.53761\n",
      "  0.4855    0.50803  -0.27815   0.77234  -1.4666   -0.45942   0.26933\n",
      "  0.33678  -0.36631   1.0428    0.7383    0.42628   0.67481  -0.16776\n",
      "  0.2546   -0.8961   -0.65298   0.98143   0.46095  -0.030374  0.9039\n",
      " -0.36815 ]\n",
      "girona [ 0.69573   0.16443  -0.61718  -0.13909  -1.2492   -0.47829   0.50206\n",
      "  1.0136   -1.0403    1.1929    1.3871   -0.88079   0.54227  -0.90985\n",
      " -0.1475   -0.18127  -0.35494   0.63054   0.1464    1.1372   -0.71314\n",
      " -0.61257  -0.44408   1.2782   -0.1732    0.30406  -0.30278   0.071796\n",
      " -0.44694  -0.40649   0.052338  0.95847  -0.58593   0.2334    0.15939\n",
      "  0.25142  -0.07162   0.41319   0.59714   0.78175   0.61157   0.039563\n",
      " -0.2227   -0.83295  -1.2992    0.11728   0.29288  -0.067999  0.49122\n",
      " -1.121   ]\n",
      "lleida [ 0.23779  -0.70155  -1.123     0.36108  -1.1387   -0.49992   0.28795\n",
      "  0.87089  -0.32366   0.85312   1.5365   -1.2579    0.45029  -0.87621\n",
      " -0.3849   -0.45242  -1.0222    0.90672   0.60101   0.89574  -1.5187\n",
      " -0.54763  -0.23907   1.3125   -0.30361   0.95009  -0.84021  -0.1023\n",
      " -0.41569  -0.24651   0.20699   0.85849  -0.80493   0.55103   0.3738\n",
      "  0.39285   0.50441   0.77364   0.73249   0.94046   0.072068 -0.46804\n",
      " -1.0545   -0.48751  -1.0242    1.0787    0.25623   0.24465   0.1344\n",
      " -0.66684 ]\n",
      "tourist [ 0.97263   1.0474   -0.25339   0.50992  -0.079486 -0.87991  -1.5079\n",
      " -0.22672   1.08      0.048978  0.018205 -0.70902   0.9513    0.26561\n",
      "  0.72587   0.16435   0.43399   0.15015  -0.5252    0.39367   0.71189\n",
      " -0.018511 -1.4629    1.0692    0.33531  -0.99202  -0.36039   0.14279\n",
      "  0.47913   0.2413    2.2199    0.69557   0.65129   0.074741  0.48242\n",
      "  0.48047  -0.18957  -0.22236  -0.9266    0.42077  -0.81675   0.70776\n",
      "  1.1882   -0.32197   0.12777  -0.79299  -0.78859  -0.26432   1.4907\n",
      " -0.63973 ]\n"
     ]
    }
   ],
   "source": [
    "# Import GloVe embeddings 50D\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "word_index = {word: index for index, word in enumerate(words_set)}\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join('../data/pretrained/glove6B/glove.6B.50d.txt'))\n",
    "\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype=np.float32)\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "EMBEDDING_DIM = 50\n",
    "\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "embedding_dict = {}\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    print(word, embedding_vector)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        embedding_dict[word] = embedding_vector"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T13:05:31.206328Z",
     "start_time": "2023-05-10T13:05:27.727901Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4, 50)\n",
      "[[ 0.023693    0.13316     0.023131    0.49833     0.026874   -0.43252\n",
      "  -1.1364     -0.82001     0.22388    -0.032119   -0.069651    0.39857\n",
      "  -0.58275     0.095008   -0.023643    0.23237    -0.42441     0.65709\n",
      "   0.57802    -0.51602     1.8253      0.12951    -0.61773     0.39281\n",
      "  -0.35754    -1.6778     -0.45201    -0.47075     0.19487     0.35828\n",
      "   3.6034      0.32865     0.47288    -0.33787    -0.46234    -0.51628\n",
      "  -1.3755      0.70789     0.4648     -0.16186    -0.0961     -0.28523\n",
      "   0.30047     0.50902     0.081356   -0.015639   -0.51021     0.34585\n",
      "   0.24201     0.82237   ]\n",
      " [ 1.3315      0.72181    -0.060088    0.43948     0.18419    -1.5083\n",
      "  -0.48125     0.46037    -1.4088      1.2701      0.68031    -0.59232\n",
      "  -1.6325     -0.30376     0.87685    -0.75531    -0.37583    -0.5363\n",
      "  -1.0669      0.45537    -0.66694     0.43001    -0.69525     0.67518\n",
      "  -0.93783    -0.67933     1.1104      0.37576    -0.36894    -0.083185\n",
      "   2.0346      0.96286    -0.56629    -0.7787     -0.10705    -0.14102\n",
      "   0.07384     0.62338     0.20366     0.0076751   0.71088     0.01501\n",
      "   0.53186    -0.82256    -0.35087     0.30876    -0.065328    0.23722\n",
      "   1.4692     -0.93469   ]\n",
      " [ 0.69573     0.16443    -0.61718    -0.13909    -1.2492     -0.47829\n",
      "   0.50206     1.0136     -1.0403      1.1929      1.3871     -0.88079\n",
      "   0.54227    -0.90985    -0.1475     -0.18127    -0.35494     0.63054\n",
      "   0.1464      1.1372     -0.71314    -0.61257    -0.44408     1.2782\n",
      "  -0.1732      0.30406    -0.30278     0.071796   -0.44694    -0.40649\n",
      "   0.052338    0.95847    -0.58593     0.2334      0.15939     0.25142\n",
      "  -0.07162     0.41319     0.59714     0.78175     0.61157     0.039563\n",
      "  -0.2227     -0.83295    -1.2992      0.11728     0.29288    -0.067999\n",
      "   0.49122    -1.121     ]\n",
      " [ 0.1111145   0.5454545   0.8666667   0.65217394  0.84745765  0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy\n",
    "\n",
    "df_embedding['origin'] = df['origin']\n",
    "df_embedding['destination'] = df['destination']\n",
    "df_embedding['user_pattern'] = df['user_pattern']\n",
    "df_embedding = df_embedding[['origin', 'destination', 'user_pattern', 'scaled_date']]\n",
    "\n",
    "input_data = df_embedding[['user_pattern', 'origin', 'destination', 'scaled_date']].values.tolist()\n",
    "input_vectors = []\n",
    "for row in deepcopy(input_data):\n",
    "    row[:3] = map(lambda word: embedding_dict.get(word), row[:3])\n",
    "    input_vectors.append(np.asarray(row, dtype=np.float32))\n",
    "\n",
    "input_vectors = np.array(input_vectors)\n",
    "\n",
    "print(input_vectors.shape)\n",
    "print(input_vectors[0])\n",
    "#X_train, X_test, _, _ = train_test_split(df_embedding, df_embedding, test_size=0.3, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T13:08:08.220475Z",
     "start_time": "2023-05-10T13:08:08.188476Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Embedding Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " words_embedding (Embedding)  (None, 3, 50)            650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 650\n",
      "Trainable params: 650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Embedding, Flatten\n",
    "\n",
    "vocab_size = len(words_set)\n",
    "\n",
    "embedding_model = Sequential()\n",
    "embedding_model.add(Input(shape=(3,)))\n",
    "embedding_model.add(Embedding(input_dim= vocab_size + 1,\n",
    "                            output_dim=EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            name='words_embedding', trainable=True\n",
    "                            ))\n",
    "\n",
    "embedding_model.compile(optimizer='adam', loss='mse')\n",
    "embedding_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T13:08:15.625615Z",
     "start_time": "2023-05-10T13:08:15.602247Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Autoencoder model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 4, 50)]           0         \n",
      "                                                                 \n",
      " gru_16 (GRU)                (None, 4, 64)             22272     \n",
      "                                                                 \n",
      " gru_17 (GRU)                (None, 32)                9408      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 4)                 132       \n",
      "                                                                 \n",
      " model_13 (Functional)       (None, 4, 50)             25714     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57,526\n",
      "Trainable params: 57,526\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from keras.layers import Input, GRU, Dense, RepeatVector, TimeDistributed\n",
    "from keras.models import Model\n",
    "\n",
    "input_shape = (4, EMBEDDING_DIM)\n",
    "output_shape = (4, EMBEDDING_DIM)\n",
    "\n",
    "latent_dim = 4\n",
    "\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "encoder = GRU(64, return_sequences=True)(inputs)\n",
    "encoder = GRU(32)(encoder)\n",
    "\n",
    "latent = Dense(latent_dim)(encoder)\n",
    "\n",
    "decoder_inputs = Input(shape=(latent_dim,))\n",
    "decoder = RepeatVector(input_shape[0])(decoder_inputs)\n",
    "decoder = GRU(32, return_sequences=True)(decoder)\n",
    "decoder = GRU(64, return_sequences=True)(decoder)\n",
    "decoder_outputs = TimeDistributed(Dense(output_shape[1]))(decoder)\n",
    "\n",
    "encoder_model = Model(inputs, latent)\n",
    "decoder_model = Model(decoder_inputs, decoder_outputs)\n",
    "\n",
    "model = Model(inputs, decoder_model(latent))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T13:08:17.893948Z",
     "start_time": "2023-05-10T13:08:16.855590Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 5s 11ms/step - loss: 0.3513 - mean_squared_error: 0.3513\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2628 - mean_squared_error: 0.2628\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1745 - mean_squared_error: 0.1745\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1513 - mean_squared_error: 0.1513\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1424 - mean_squared_error: 0.1424\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1311 - mean_squared_error: 0.1311\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1223 - mean_squared_error: 0.1223\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1168 - mean_squared_error: 0.1168\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1123 - mean_squared_error: 0.1123\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1078 - mean_squared_error: 0.1078\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(input_vectors, input_vectors, epochs=10, batch_size=32, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T13:08:40.626825Z",
     "start_time": "2023-05-10T13:08:32.824530Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Make predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def find_closest_embeddings(embedding):\n",
    "    return sorted(embedding_dict.keys(), key=lambda word: spatial.distance.euclidean(embedding_dict[word], embedding))[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T17:20:10.868466Z",
     "start_time": "2023-05-09T17:20:10.860962Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input - Random passenger data: \n",
      "['business', 'madrid', 'zaragoza', array([0.        , 0.        , 0.        , 0.30434783, 0.50847458,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ])]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Output - Passenger reconstruction: \n",
      "['business', 'madrid', 'zaragoza']\n",
      "[2023, 6, 1, 7, 29]\n"
     ]
    }
   ],
   "source": [
    "random_index = np.random.randint(0, len(input_vectors))\n",
    "random_vector = input_vectors[random_index]\n",
    "\n",
    "print(\"Input - Random passenger data: \")\n",
    "print(input_data[random_index])\n",
    "\n",
    "prediction = model.predict(np.array([random_vector]))[0]\n",
    "\n",
    "print(\"Output - Passenger reconstruction: \")\n",
    "decoded_prediction = [find_closest_embeddings(word_vector) for word_vector in prediction[:3]]\n",
    "print(decoded_prediction)\n",
    "decode_date = scaler.inverse_transform(np.array([prediction[-1][:5]]))\n",
    "print([int(v) for v in decode_date[0]])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T17:35:09.371920Z",
     "start_time": "2023-05-09T17:35:09.322745Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-05T08:27:55.075132Z",
     "start_time": "2023-05-05T08:27:55.072445Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
