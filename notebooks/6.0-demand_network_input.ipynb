{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform Demand data, so it can be used by a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from typing import Tuple"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T13:55:00.137985Z",
     "end_time": "2023-05-02T13:55:01.691065Z"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Demand Data and Passenger objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-02T13:55:11.070813Z",
     "end_time": "2023-05-02T13:55:12.876443Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from src.robin.demand.entities import Demand, Passenger\n",
    "\n",
    "path_config_demand = '../configs/test_case/demand_data.yml'\n",
    "\n",
    "demand = Demand.from_yaml(path_config_demand)\n",
    "\n",
    "passengers = demand.generate_passengers()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get passenger relevant information and save it in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  user_pattern origin destination  arrival_day arrival_time\n",
      "0     business  60000       04040      19509.0     8.303621\n",
      "1     business  60000       04040      19509.0     9.698859\n",
      "2     business  60000       04040      19509.0     8.382808\n",
      "3     business  60000       04040      19509.0     8.172194\n",
      "4     business  60000       04040      19509.0     8.950174\n"
     ]
    }
   ],
   "source": [
    "def get_passenger_info(passenger: Passenger) -> Tuple[str, str, str, datetime.datetime, float]:\n",
    "    \"\"\"\n",
    "    Get the information of a passenger and return it as a tuple\n",
    "\n",
    "    Args:\n",
    "        passenger: Passenger object\n",
    "\n",
    "    Returns:\n",
    "        Tuple[str, str, str, datetime.date, float]: Tuple with the information of the passenger\n",
    "    \"\"\"\n",
    "    user_pattern = passenger.user_pattern.name\n",
    "    origin, destination = passenger.market.departure_station, passenger.market.arrival_station\n",
    "    arrival_day = datetime.datetime.combine(passenger.arrival_day.date, datetime.datetime.min.time())\n",
    "    arrival_time = np.asarray(passenger.arrival_time).astype(np.float32)\n",
    "    return user_pattern.lower(), origin, destination, arrival_day, arrival_time\n",
    "\n",
    "# Map a list of Passenger objects to a list of tuples with the passenger information\n",
    "passengers_info = list(map(get_passenger_info, passengers))\n",
    "\n",
    "# Dataframe with the passenger information\n",
    "df = pd.DataFrame(passengers_info, columns=['user_pattern', 'origin', 'destination', 'arrival_day', 'arrival_time'])\n",
    "\n",
    "def elapsed_days(date: datetime.datetime) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Returns the number of days elapsed since the first day of the year.\n",
    "\n",
    "    Args:\n",
    "        date (datetime.datetime): Datetime object.\n",
    "\n",
    "    Returns:\n",
    "        int: Number of days elapsed since the first day of the year.\n",
    "    \"\"\"\n",
    "    reference_date = datetime.datetime(1970, 1, 1)\n",
    "    return np.asarray((date - reference_date).days * 1.0).astype(np.float32)\n",
    "\n",
    "\n",
    "df['arrival_day'] = df['arrival_day'].apply(elapsed_days)\n",
    "print(df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T13:55:12.876652Z",
     "end_time": "2023-05-02T13:55:12.955128Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Map stations IDs to Stations names"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  user_pattern  origin destination  arrival_day arrival_time\n",
      "0     business  madrid    zaragoza      19509.0     8.303621\n",
      "1     business  madrid    zaragoza      19509.0     9.698859\n",
      "2     business  madrid    zaragoza      19509.0     8.382808\n",
      "3     business  madrid    zaragoza      19509.0     8.172194\n",
      "4     business  madrid    zaragoza      19509.0     8.950174\n"
     ]
    }
   ],
   "source": [
    "stations_csv_path = f'../data/renfe/renfe_stations.csv'\n",
    "\n",
    "def get_renfe_station_id(adif_id: str, stations_df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Returns the Station name given the Adif station id.\n",
    "\n",
    "    Args:\n",
    "        adif_id (str): Adif station id.\n",
    "        stations_df (pd.DataFrame): Dataframe with the stations' information.\n",
    "\n",
    "    Returns:\n",
    "        str: Station name.\n",
    "    \"\"\"\n",
    "    station_name = stations_df[stations_df['stop_id'] == adif_id]['stop_name'].values[0]\n",
    "    station_name = station_name.replace(\"-\", \" \").split(\" \")[0].lower()\n",
    "    return station_name\n",
    "\n",
    "stations_df = pd.read_csv(stations_csv_path, dtype={'stop_id': str, 'renfe_id': str})\n",
    "\n",
    "df['origin'] = df['origin'].apply(get_renfe_station_id, args=(stations_df,))\n",
    "df['destination'] = df['destination'].apply(get_renfe_station_id, args=(stations_df,))\n",
    "\n",
    "print(df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T13:55:12.954398Z",
     "end_time": "2023-05-02T13:55:17.158513Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Autoencoder Model\n",
    "\n",
    "## NOT FUNCTIONAL YET!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import pre-trained GloVe embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'student', 'business', 'zaragoza', 'madrid', 'barcelona'}\n"
     ]
    }
   ],
   "source": [
    "# Get bag of words\n",
    "words_set = set(df[['user_pattern', 'origin', 'destination']].values.flatten())\n",
    "\n",
    "print(words_set)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T13:55:17.161997Z",
     "end_time": "2023-05-02T13:55:17.167854Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n",
      "student [-1.0729    0.94103   0.084904 -1.0766    0.42866   0.099877 -0.51081\n",
      " -0.24961  -0.30883   0.19553   0.1965   -0.73152   0.096916 -0.062686\n",
      "  0.12078  -0.72384  -0.382     0.6934    0.32956   0.40244   0.53485\n",
      "  0.91781  -0.44553   0.71804  -0.13635  -1.6906    0.15818  -1.2367\n",
      " -1.2278   -0.058566  2.7544    0.18672  -0.263    -1.2792    0.16992\n",
      "  0.40748   0.12248   0.11211   0.78318   0.036392 -0.40808  -0.058474\n",
      " -0.27932   0.33035   0.52384  -1.0487    0.27565   0.0363    0.048604\n",
      "  0.28239 ]\n",
      "business [ 0.023693  0.13316   0.023131  0.49833   0.026874 -0.43252  -1.1364\n",
      " -0.82001   0.22388  -0.032119 -0.069651  0.39857  -0.58275   0.095008\n",
      " -0.023643  0.23237  -0.42441   0.65709   0.57802  -0.51602   1.8253\n",
      "  0.12951  -0.61773   0.39281  -0.35754  -1.6778   -0.45201  -0.47075\n",
      "  0.19487   0.35828   3.6034    0.32865   0.47288  -0.33787  -0.46234\n",
      " -0.51628  -1.3755    0.70789   0.4648   -0.16186  -0.0961   -0.28523\n",
      "  0.30047   0.50902   0.081356 -0.015639 -0.51021   0.34585   0.24201\n",
      "  0.82237 ]\n",
      "zaragoza [ 1.0642    0.089939 -0.28715   0.82471   0.31063  -1.4798    0.12028\n",
      "  0.7449   -1.2919    0.39737   0.4715   -0.53483  -0.48049  -1.2998\n",
      "  0.32826  -1.3085   -0.67916  -0.20625  -0.7232    0.41638  -1.2895\n",
      " -0.69963  -0.23631   0.70175  -0.61498   0.20193   1.329     0.25294\n",
      " -0.093715 -0.16535   0.99605   1.2007   -0.26729  -0.42035  -0.15881\n",
      "  0.63906  -0.73977   1.3119    0.61136  -0.59197   1.3032    0.16094\n",
      " -0.027686 -0.9412   -0.68288   0.65116   0.47976  -0.32516   1.3912\n",
      " -0.50467 ]\n",
      "madrid [ 1.3315     0.72181   -0.060088   0.43948    0.18419   -1.5083\n",
      " -0.48125    0.46037   -1.4088     1.2701     0.68031   -0.59232\n",
      " -1.6325    -0.30376    0.87685   -0.75531   -0.37583   -0.5363\n",
      " -1.0669     0.45537   -0.66694    0.43001   -0.69525    0.67518\n",
      " -0.93783   -0.67933    1.1104     0.37576   -0.36894   -0.083185\n",
      "  2.0346     0.96286   -0.56629   -0.7787    -0.10705   -0.14102\n",
      "  0.07384    0.62338    0.20366    0.0076751  0.71088    0.01501\n",
      "  0.53186   -0.82256   -0.35087    0.30876   -0.065328   0.23722\n",
      "  1.4692    -0.93469  ]\n",
      "barcelona [ 0.68944   1.2217   -0.23655   0.36109  -0.62116  -1.0075   -0.52565\n",
      "  0.65766  -1.2764    1.1286    1.1386   -0.36088  -1.3849   -0.58442\n",
      "  0.9772   -0.35103   0.29237  -0.27426  -1.3109   -0.015967 -1.0695\n",
      "  0.11901  -0.56335   0.49648  -0.44571  -0.47566   0.79045   0.42923\n",
      " -0.76743  -0.14029   1.7552    1.3342   -0.42864  -0.29125  -0.2056\n",
      "  0.21055   0.099324  1.4187    0.34068  -0.4477    1.0795    0.10387\n",
      "  0.15772  -0.51013  -0.50933   0.25395   0.050859 -0.084172  0.69738\n",
      " -1.192   ]\n"
     ]
    }
   ],
   "source": [
    "# Import GloVe embeddings 50D\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "word_index = {word: index for index, word in enumerate(words_set)}\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join('../data/pretrained/glove6B/glove.6B.50d.txt'))\n",
    "\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype=np.float32)\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "EMBEDDING_DIM = 50\n",
    "\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    print(word, embedding_vector)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T14:01:45.408025Z",
     "end_time": "2023-05-02T14:01:48.693747Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.023693   0.13316    0.023131   0.49833    0.026874  -0.43252\n",
      "  -1.1364    -0.82001    0.22388   -0.032119  -0.069651   0.39857\n",
      "  -0.58275    0.095008  -0.023643   0.23237   -0.42441    0.65709\n",
      "   0.57802   -0.51602    1.8253     0.12951   -0.61773    0.39281\n",
      "  -0.35754   -1.6778    -0.45201   -0.47075    0.19487    0.35828\n",
      "   3.6034     0.32865    0.47288   -0.33787   -0.46234   -0.51628\n",
      "  -1.3755     0.70789    0.4648    -0.16186   -0.0961    -0.28523\n",
      "   0.30047    0.50902    0.081356  -0.015639  -0.51021    0.34585\n",
      "   0.24201    0.82237  ]\n",
      " [ 1.3315     0.72181   -0.060088   0.43948    0.18419   -1.5083\n",
      "  -0.48125    0.46037   -1.4088     1.2701     0.68031   -0.59232\n",
      "  -1.6325    -0.30376    0.87685   -0.75531   -0.37583   -0.5363\n",
      "  -1.0669     0.45537   -0.66694    0.43001   -0.69525    0.67518\n",
      "  -0.93783   -0.67933    1.1104     0.37576   -0.36894   -0.083185\n",
      "   2.0346     0.96286   -0.56629   -0.7787    -0.10705   -0.14102\n",
      "   0.07384    0.62338    0.20366    0.0076751  0.71088    0.01501\n",
      "   0.53186   -0.82256   -0.35087    0.30876   -0.065328   0.23722\n",
      "   1.4692    -0.93469  ]\n",
      " [ 1.0642     0.089939  -0.28715    0.82471    0.31063   -1.4798\n",
      "   0.12028    0.7449    -1.2919     0.39737    0.4715    -0.53483\n",
      "  -0.48049   -1.2998     0.32826   -1.3085    -0.67916   -0.20625\n",
      "  -0.7232     0.41638   -1.2895    -0.69963   -0.23631    0.70175\n",
      "  -0.61498    0.20193    1.329      0.25294   -0.093715  -0.16535\n",
      "   0.99605    1.2007    -0.26729   -0.42035   -0.15881    0.63906\n",
      "  -0.73977    1.3119     0.61136   -0.59197    1.3032     0.16094\n",
      "  -0.027686  -0.9412    -0.68288    0.65116    0.47976   -0.32516\n",
      "   1.3912    -0.50467  ]]\n",
      "(8380, 3, 50)\n"
     ]
    }
   ],
   "source": [
    "input_data = df[['user_pattern', 'origin', 'destination']].values.tolist()\n",
    "\n",
    "input_vectors = np.array([np.array(list(map(lambda word: embeddings_index.get(word), row))) for row in input_data])\n",
    "\n",
    "print(input_vectors[0])\n",
    "print(input_vectors.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T14:01:52.348762Z",
     "end_time": "2023-05-02T14:01:52.389699Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Embedding Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " words_embedding (Embedding)  (None, 3, 50)            300       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 300\n",
      "Trainable params: 300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-02 14:02:02.631527: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Embedding, Flatten\n",
    "\n",
    "vocab_size = len(words_set)\n",
    "\n",
    "embedding_model = Sequential()\n",
    "embedding_model.add(Input(shape=(3,)))\n",
    "embedding_model.add(Embedding(input_dim= vocab_size + 1,\n",
    "                            output_dim=EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            name='words_embedding', trainable=True\n",
    "                            ))\n",
    "\n",
    "embedding_model.compile(optimizer='adam', loss='mse')\n",
    "embedding_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T14:01:57.688159Z",
     "end_time": "2023-05-02T14:02:02.688581Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 3, 50)]           0         \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 3, 64)             22272     \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 32)                9408      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 132       \n",
      "                                                                 \n",
      " model_1 (Functional)        (None, 3, 50)             25714     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57,526\n",
      "Trainable params: 57,526\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, GRU, Dense, RepeatVector, TimeDistributed\n",
    "from keras.models import Model\n",
    "\n",
    "input_shape = (3, 50)\n",
    "output_shape = (3, 50)\n",
    "\n",
    "latent_dim = 4\n",
    "\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "encoder = GRU(64, return_sequences=True)(inputs)\n",
    "encoder = GRU(32)(encoder)\n",
    "\n",
    "latent = Dense(latent_dim)(encoder)\n",
    "\n",
    "decoder_inputs = Input(shape=(latent_dim,))\n",
    "decoder = RepeatVector(input_shape[0])(decoder_inputs)\n",
    "decoder = GRU(32, return_sequences=True)(decoder)\n",
    "decoder = GRU(64, return_sequences=True)(decoder)\n",
    "decoder_outputs = TimeDistributed(Dense(output_shape[1]))(decoder)\n",
    "\n",
    "encoder_model = Model(inputs, latent)\n",
    "decoder_model = Model(decoder_inputs, decoder_outputs)\n",
    "\n",
    "model = Model(inputs, decoder_model(latent))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T14:02:07.774104Z",
     "end_time": "2023-05-02T14:02:09.066240Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "262/262 [==============================] - 7s 7ms/step - loss: 0.1134 - accuracy: 0.8165\n",
      "Epoch 2/10\n",
      "262/262 [==============================] - 2s 7ms/step - loss: 0.0157 - accuracy: 0.9186\n",
      "Epoch 3/10\n",
      "262/262 [==============================] - 2s 7ms/step - loss: 0.0012 - accuracy: 0.9929\n",
      "Epoch 4/10\n",
      "262/262 [==============================] - 2s 7ms/step - loss: 1.1030e-04 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "262/262 [==============================] - 2s 7ms/step - loss: 4.5483e-05 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "262/262 [==============================] - 2s 7ms/step - loss: 3.6829e-05 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "262/262 [==============================] - 2s 7ms/step - loss: 3.1376e-05 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "262/262 [==============================] - 2s 7ms/step - loss: 1.9711e-05 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "262/262 [==============================] - 2s 7ms/step - loss: 2.2504e-05 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "262/262 [==============================] - 2s 7ms/step - loss: 8.2643e-06 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7fa811b09af0>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(input_vectors, input_vectors, epochs=10, batch_size=32, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T14:02:11.498518Z",
     "end_time": "2023-05-02T14:02:34.367796Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def find_closest_word(v):\n",
    "    closest_word = None\n",
    "    closest_distance = float('inf')\n",
    "    for word, vector in embeddings_index.items():\n",
    "        distance = cosine_similarity(v, vector)\n",
    "        if distance < closest_distance:\n",
    "            closest_distance = distance\n",
    "            closest_word = word\n",
    "    return closest_word\n",
    "\n",
    "def cosine_similarity(u, v):\n",
    "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T14:02:36.331343Z",
     "end_time": "2023-05-02T14:02:36.346084Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.023693  0.13316   0.023131  0.49833   0.026874 -0.43252  -1.1364\n",
      " -0.82001   0.22388  -0.032119 -0.069651  0.39857  -0.58275   0.095008\n",
      " -0.023643  0.23237  -0.42441   0.65709   0.57802  -0.51602   1.8253\n",
      "  0.12951  -0.61773   0.39281  -0.35754  -1.6778   -0.45201  -0.47075\n",
      "  0.19487   0.35828   3.6034    0.32865   0.47288  -0.33787  -0.46234\n",
      " -0.51628  -1.3755    0.70789   0.4648   -0.16186  -0.0961   -0.28523\n",
      "  0.30047   0.50902   0.081356 -0.015639 -0.51021   0.34585   0.24201\n",
      "  0.82237 ]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[ 0.02456567  0.13129832  0.02502798  0.5006918   0.02502276 -0.4316616\n",
      " -1.1384692  -0.82017046  0.22513187 -0.03172892 -0.07253777  0.39885285\n",
      " -0.5834179   0.0957551  -0.02553883  0.23468322 -0.4250054   0.65818304\n",
      "  0.5786389  -0.5170093   1.8293579   0.12932485 -0.61550206  0.39219365\n",
      " -0.35675097 -1.6787056  -0.45541212 -0.46804282  0.19626822  0.3579564\n",
      "  3.6055553   0.3279195   0.47633848 -0.3374651  -0.46280885 -0.51941293\n",
      " -1.3786279   0.7089366   0.46431392 -0.1617189  -0.09687971 -0.28614634\n",
      "  0.3034656   0.5093979   0.08122537 -0.01347204 -0.5121624   0.34608686\n",
      "  0.2404534   0.8243374 ]\n",
      "vogan\n",
      "caylor\n",
      "vyse\n"
     ]
    }
   ],
   "source": [
    "random_index = np.random.randint(0, len(input_vectors))\n",
    "random_vector = input_vectors[random_index]\n",
    "\n",
    "print(random_vector[0])\n",
    "\n",
    "prediction = model.predict(np.array([random_vector]))[0]\n",
    "\n",
    "print(prediction[0])\n",
    "\n",
    "for word_vector in prediction:\n",
    "    print(find_closest_word(word_vector))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T14:04:13.251465Z",
     "end_time": "2023-05-02T14:04:22.415691Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
